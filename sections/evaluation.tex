\chapter{Evaluation}

In this chapter, we will evaluate and discuss the performance of our polymorphic interpreter on six microbenchmarks.
We use an existing set of benchmarks from \cite{scala:miniboxing} as they exercise many features of the Scala runtime that require specialization to perform optimally.
We will evaluate performance of these benchmarks on the monomorphic interpreter as well as Scala bytecode on GraalVM as points of comparison for relative performance.
Finally, we will discuss the results of the benchmarks.

\section{Benchmarks}
\begin{figure}[!htb]
	\begin{minted}{scala}
	class ArrayBuffer[T] {
		protected def initialSize: Int = 16
		var size0 = 0
		var array: Array[T] = newArray[T](Math.max(initialSize, 1))
		
		def length: Int = size0
		
		private def get(i: Int): T = array(i)
		private def set(i: Int, elem: T): Unit = array(i) = elem
		
		def contains(elem: T): Boolean = {
			var i = 0
			while (i < size0) {
				if (array(i) == elem) return true
				i += 1
			}
			false
		}
		
		def reverse(): Unit = {
			var pos = 0
			while (pos * 2 < size0) {
				swap(pos, size0 - pos - 1) // swaps two elements in the array
				pos += 1
			}
		}
		
		def append(elem: T): Unit = {
			val newSize0 = size0 + 1
			ensureSize(newSize0)
			set(size0, elem)
			size0 = newSize0
		}
		
		// Ensure that the internal array has at least `n` cells. 
		def ensureSize(n: Int): Unit = {
			val arrayLength: Long = array.length // Use a Long to prevent overflows
			if (n > arrayLength) {
				var newSize: Long = arrayLength * 2
				while (n > newSize)
					newSize = newSize * 2
				// Clamp newSize to Int.MaxValue
				if (newSize > lang.Int.MaxValue) newSize = lang.Int.MaxValue
				
				val resized = newArray[T](newSize.toInt)
				var i = 0
				while (i < size0) {
					resized(i) = get(i)
					i += 1
				}
				array = resized
			}
		}
	\end{minted}
	\caption{Code of the \scalainline{ArrayBuffer} benchmark.}
	\label{example:arraybuffer-benchmark}
\end{figure}

In this section, we will introduce an additional program on top of our running example for benchmarking.
We will also summarize the motivations from \cite{scala:miniboxing} for the selection of these benchmarks.

Each microbenchmark exercises unique polymorphic operations which are typically performance bottlenecks\cite{scala:collections-optimization}\cite{scala:dacapo} in Scala programs.
The \scalainline{ArrayBuffer} class is an implementation of a resizable buffer backed by an array.
It contains three microbenchmarks which stress polymorphic operations in the context of contiguous memory access.

The \scalainline{List} class is the implementation of a linked list that we have used as the running example in this thesis.
We use the \scalainline{List} class to evaluate polymorphic operations in the context of random heap access.
Like the \scalainline{ArrayBuffer} benchmarks, there is an \scalainline{append} and \scalainline{contains} microbenchmark.
We will use lists to test the performance of polymorphic hash computations using \scalainline{List.hashCode}.

\section{Methodology}

Performance measurement of just-in-time compiled programs is an infamously difficult issue\cite{java:performance-analysis}\cite{java:statistically-rigor-performance-analysis}.
Many non-deterministic effects, such as speculative optimization, garbage collection, thread scheduling to name a few, affect the performance of programs executing on the Java Virtual Machine.
As result, the JVM must be \textit{warmed up} prior to measure of program performance.
A benchmarking routine is warmed up with several iterations of invocations in order for profiling data to be collected and JIT compilation to finished.
Therefore the measured performance of a microbenchmark will record the program executing the stable JIT compiled code instead of code executing in the interpreter.

Each benchmark method in this chapter is warmed up with $10$ iterations of warmup lasting $10$ seconds each.
Results of these is measured in throughput, the number of executions that successfully completed in a second.
The results are averaged from $10$ measurements iterations for a period of $10$ seconds each.
We evaluate our microbenchmarks on input sizes between one hundred thousand and one million elements to account for factors of memory in our benchmarks. 
Each benchmark is run on three different implementations, Scala on GraalVM (Graal), the monomorphic interpreter (Mono), and the polymorphic interpreter (Poly).

\section{Experimental Results}

\begin{figure}[!htb]
	\centering
	\includesvg[width=\textwidth]{data/ArrayBuffer.Append.svg}
	\caption{Benchmark results for \scalainline{ArrayBuffer.append}.}
\end{figure}

The benchmark for \scalainline{ArrayBuffer.append} inserts a sequence of elements into a newly initialized array buffer. 
This benchmark stresses array memory movement.
Each time the backing array is too small for an additional element, the backing array is resized by creating a new larger and copying over existing elements.
This resizing operation (\scalainline{ensureSize} in \ref{example:arraybuffer-benchmark}) dominates the time spent in execution.
Because of this bottleneck, executing compiled Scala bytecode on GraalVM is up to 4 times faster than the monomorphic and polymorphic interpreter.

\begin{figure}[!htb]
	\centering
	\includesvg[width=\textwidth]{data/ArrayBuffer.Contains.svg}
	\caption{Benchmark results for \scalainline{ArrayBuffer.contains}.}
\end{figure}

The \scalainline{ArrayBuffer.contains} benchmark tests array operations in isolation. 
The benchmark checks an array buffer for the existence of a element.
It exercises a polymorphic array access followed by a polymorphic equality operation (e.g. \scalainline{(x: T) == (y: T)}).
A polymorphic equality operator is dispatched the \javainline{equals} method of its left hand side argument.
This results in the boxing of one or both arguments in equality checks between polymorphic values.

\begin{figure}[!htb]
	\centering
	\includesvg[width=\textwidth]{data/ArrayBuffer.Reverse.svg}
	\caption{Benchmark results for \scalainline{ArrayBuffer.reverse}.}
\end{figure}

\scalainline{ArrayBuffer.reverse} reverses the order of the elements in the array buffer.
Reversing an array is performance-bound by the loop of swap operations.
A swap operation (given in \ref{impl:swap}) consists of two polymorphic value definitions (frame writes) initialized from polymorphic array accesses followed by the inverse of those two operations.

\begin{figure}[!htb]
\begin{minted}{scala}
	def swap(i: Int, j: Int): Unit = {
		val tmp1: T = get(i)
		val tmp2: T = get(j)
		set(i, tmp2)
		set(j, tmp1)
	}
\end{minted}
\caption{Code to swap two elements in an array buffer}
\label{impl:swap}
\end{figure}

The optimization of this microbenchmark proved to be the most difficult benchmark in terms of matching hand written monomorphic code in \cite{scala:miniboxing}.
The performance between the monomorphic interpreter and GraalVM is roughly equal between all types; 
Neither implementation is able to specialize the polymorphic reads and array accesses.
The polymorphic interpreter has up to $25$ times more throughput than the monomorphic interpreter and GraalVM.

\begin{figure}[!htb]
	\centering
	\includesvg[width=\textwidth]{data/List.Append.svg}
	\caption{Benchmark results for \scalainline{List.append}.}
\end{figure}

The \scalainline{List.append} benchmark constructs a list from an array.
As the creation of polymorphic instances is predominantly memory-bound and not compute-bound, there is no significant improvement in throughput from specialization.
In fact, executing Scala via Java bytecode on the JMV results in substantially greater throughput.

\begin{figure}[!htb]
	\centering
	\includesvg[width=\textwidth]{data/List.Contains.svg}
	\caption{Benchmark results for \scalainline{List.contains}.}
\end{figure}

Like \scalainline{ArrayBuffer.contains} exercises the same performance-bottlenecks as the \scalainline{ArrayBuffer.contains} except under the context of random heap access for a list.
The polymorphic interpreter 

\begin{figure}[!htb]
	\centering
	\includesvg[width=\textwidth]{data/List.Hashcode.svg}
	\caption{Benchmark results for \scalainline{List.hashCode}.}
\end{figure}

\begin{figure}[!htb]
\begin{minted}{java}
	public static int anyHash(Object x) {
		if (x == null)           return 0;
		if (x instanceof Long)   return longHash(((Long) x).longValue());
		if (x instanceof Double) return doubleHash(((java.lang.Double) x).doubleValue());
		if (x instanceof Float)  return floatHash(((Float) x).floatValue());
		
		return x.hashCode();
	}
\end{minted}
\caption{Implementation of the \scalainline{anyHash} function.}
\label{impl:anyHash}
\end{figure}

\scalainline{List.hashCode} tests the specialization of the hash code function.
Every class in Scala inherits the \scalainline{hashCode} function from the $\top$ type.
When the \scalainline{hashCode} method is invoked in a polymorphic context, the Scala compiler inserts the \scalainline{anyHash} bridge.
The semantics of computing hash codes between on the same values with differing types such as \scalainline{Int} and \scalainline{Long} necessitates the insertion of this bridge, which complicates JIT complication.

Figure \ref{impl:anyHash} gives the implementation of the \scalainline{anyHash} function.
In the \scalainline{Int} and \scalainline{Long} invocations of \scalainline{List.hashCode}, the polymorphic interpreter keeps parity with the implementation of Scala on GraalVM.
In the \scalainline{Double} invocation of \scalainline{List.hashCode}, the throughput on the polymorphic interpreter is $2.5$ times greater than that the implementation of the monomorphic interpreter.





